import pandas as pd
import uproot
import numpy as np


def pileup(singles_before_pileup: pd.DataFrame, time_window: float):
    """
    This function simulates pile-up with the given time window in ns.
    The singles_before_pileup are in a pandas DataFrame.
    It returns a dict in which the keys are volume IDs, and the values are a pandas DataFrame
    representing the singles for that volume ID after pile-up.
    Each single after pile-up has:
    - GlobalTime taken from the first contributing single.
    - TotalEnergyDeposit equal to the sum of all singles in the same time window.
    - PostPosition equal to the energy-weighted position of all contributing singles.
    The other attributes are taken from the single in the time window that has the
    highest TotalEnergyDeposit.
    """
    df = singles_before_pileup  # df for DataFrame
    grouped = df.groupby("PreStepUniqueVolumeID")

    singles_after_pileup = {}
    for volume_id, group in grouped:
        # For each volume, start with a sorted list of singles time values in ns.
        group = group.sort_values("GlobalTime")
        times = group["GlobalTime"].values

        current = 0  # index of a single that opens the current time window
        next_single = 1
        while next_single < len(times):
            # Increment next until it points to the single that opens the next time window.
            while (
                next_single < len(times)
                and times[next_single] <= times[current] + time_window
            ):
                next_single += 1
            if next_single > current + 1:
                # We have found a group of at least two singles in the same time window.
                # Find the single with the highest TotalEnergyDeposit in the time window.
                group_slice = group.iloc[current:next_single]
                max_energy_idx = group_slice["TotalEnergyDeposit"].idxmax()
                # Create a single with the attribute values from the max energy single,
                # except for the TotalEnergyDeposit, GlobalTime and PostPosition.
                pileup_row = group.loc[max_energy_idx].copy()
                # Energy is the sum of energies of all contributing singles.
                pileup_row["TotalEnergyDeposit"] = group_slice[
                    "TotalEnergyDeposit"
                ].sum()
                # Time is taken from the first contributing single.
                pileup_row["GlobalTime"] = group_slice["GlobalTime"].iloc[0]
                # PostPosition is the energy-weighted sum of positions from all contributing singles.
                pileup_row["PostPosition_X"] = (
                    group_slice["PostPosition_X"] * group_slice["TotalEnergyDeposit"]
                ).sum() / group_slice["TotalEnergyDeposit"].sum()
                pileup_row["PostPosition_Y"] = (
                    group_slice["PostPosition_Y"] * group_slice["TotalEnergyDeposit"]
                ).sum() / group_slice["TotalEnergyDeposit"].sum()
                pileup_row["PostPosition_Z"] = (
                    group_slice["PostPosition_Z"] * group_slice["TotalEnergyDeposit"]
                ).sum() / group_slice["TotalEnergyDeposit"].sum()
                # Add the combined single to the output.
                singles_after_pileup.setdefault(volume_id, []).append(pileup_row)
                # Update current and next for the next time window.
                current = next_single
                next_single = current + 1
            else:
                # The time window opened by current contains only contains one event.
                # Add the original single to the output unchanged.
                singles_after_pileup.setdefault(volume_id, []).append(
                    group.iloc[current]
                )
                # Update current and next for the next time window.
                current += 1
                next_single += 1
            # If there is only one single left, add it to the output unchanged.
            if current == len(times) - 1:
                singles_after_pileup.setdefault(volume_id, []).append(
                    group.iloc[current]
                )

    return singles_after_pileup


def check_gate_pileup(
    root_file_path: str,
    name_before_pileup: str,
    name_after_pileup: str,
    time_window: float,
):
    """
    This function checks that the singles generated by GateDigitizerPileupActor are identical
    to the ones generated by the Python pile-up implementation in the pileup() function above.
    """
    with uproot.open(root_file_path) as root_file:
        singles_before_pileup = root_file[name_before_pileup].arrays(library="pd")
        actual_singles_after_pileup = root_file[name_after_pileup].arrays(library="pd")

    expected_singles_after_pileup = pileup(singles_before_pileup, time_window)
    num_expected_singles = sum(
        len(entries) for entries in expected_singles_after_pileup.values()
    )

    print(f"Singles before pile-up: {len(singles_before_pileup)}")
    print(
        f"Expected singles after pile-up: {num_expected_singles} ({num_expected_singles / len(singles_before_pileup) * 100:.01f}%)"
    )
    print(f"Actual singles after pile-up: {len(actual_singles_after_pileup)}")

    all_match = True
    for volume_id in expected_singles_after_pileup.keys():

        # Get the expected singles (Python) and actual singles (GateDigitizerPileupActor) for the current volume.
        expected_singles = pd.DataFrame(expected_singles_after_pileup[volume_id])
        actual_singles = actual_singles_after_pileup[
            actual_singles_after_pileup["PreStepUniqueVolumeID"] == volume_id
        ].reset_index(drop=True)

        # Compare the number of singles
        if len(expected_singles) != len(actual_singles):
            print(
                f"Volume {volume_id}: Expected {len(expected_singles)} singles, got {len(actual_singles)}"
            )
            all_match = False
            continue

        # Compare all attributes, except the volume ID
        for attr in expected_singles.columns:
            if attr == "PreStepUniqueVolumeID":
                continue
            expected_values = expected_singles[attr].values
            actual_values = actual_singles[attr].values
            if np.issubdtype(expected_values.dtype, np.floating):
                if not np.allclose(expected_values, actual_values, rtol=1e-9):
                    print(f"Volume {volume_id}: Attribute {attr} does not match")
                    all_match = False
                    break
            else:
                if not all(expected_values == actual_values):
                    print(f"Volume {volume_id}: Attribute {attr} does not match")
                    all_match = False
                    break

    return all_match
